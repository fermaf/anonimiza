# anonimiza
Anonimiza datos personales. MML analiza sistematicamente texto (ej. en documentos  p√∫blicos del Estado)  y anonimiza seg√∫n normativa de protecci√≥n a datos personales. As√≠:
* El Estado no tiene pretexto para cumplir con que sus actos son p√∫blicos (por regla general).
* Las personas siempre recibir√°n inforamaci√≥n del Estado.
* El Estado se modernizaü§© (empieza a hacerse eficiente (hasta que sea inecesario ü§òüî•‚úÖ)
  
Utilizando herramientas m√°gicas :) HuggingsFace, Langchain para gestionar LLM (Large Lenguaje Models) como OpenAI, se podr√≠a solucionar si de de forma abastracta hacer una planificaci√≥n cognicitiva de,  con tareas jerarquerizadas (o no), razonar en como resolverlo.


...En este doc, de ac√° en adelantees, ser√° una AI la que escribe mayopritariamente.


## Introducci√≥n

En la era digital actual, la protecci√≥n de los datos personales se ha convertido en una preocupaci√≥n primordial. Este ebook tiene como objetivo proporcionar una gu√≠a sobre c√≥mo utilizar las herramientas de Modelos de Lenguaje de Aprendizaje Autom√°tico (LLMs) gestionadas por Langchain y OpenAI para anonimizar datos personales en documentos PDF, de acuerdo con la normativa vigente en Chile sobre protecci√≥n de datos personales.

## Conceptos clave

*Datos personales: Cualquier informaci√≥n que se refiere a una persona f√≠sica identificada o identificable.

*Anonimizaci√≥n: Proceso de eliminaci√≥n o alteraci√≥n de datos personales de tal manera que la persona a la que se refieren no pueda ser identificada.

*Pseudonimizaci√≥n: Proceso de reemplazo de datos personales con pseud√≥nimos o identificadores que no revelan la identidad de la persona a la que se refieren.

*Normativa de protecci√≥n de datos en Chile: Conjunto de leyes y regulaciones que rigen la recopilaci√≥n, almacenamiento, uso y divulgaci√≥n de datos personales en Chile.

*Descripci√≥n de las herramientas de LLMs

Las herramientas de LLMs gestionadas por Langchain y OpenAI son sistemas de inteligencia artificial que pueden entender, generar y traducir texto en lenguaje natural. Estas herramientas pueden ser entrenadas para realizar una variedad de tareas, incluyendo la identificaci√≥n y anonimizaci√≥n de datos personales en documentos de texto.

## Proceso de anonimizaci√≥n de datos

El proceso de anonimizaci√≥n de datos personales en documentos PDF utilizando las herramientas de LLMs incluye los siguientes pasos:

* Carga del documento PDF en la herramienta de LLM.
* Identificaci√≥n de los datos personales en el documento utilizando el modelo de lenguaje.
* Anonimizaci√≥n de los datos identificados, ya sea elimin√°ndolos o reemplaz√°ndolos con pseud√≥nimos.
* Verificaci√≥n de que todos los datos personales han sido correctamente anonimizados.
* Consideraciones legales y √©ticas

Es importante tener en cuenta las leyes y regulaciones de protecci√≥n de datos en Chile al anonimizar datos personales. Adem√°s, tambi√©n es crucial considerar las implicaciones √©ticas de la anonimizaci√≥n de datos, como el respeto a la privacidad y la confidencialidad.

## Conclusi√≥n y pr√≥ximos pasos

## Referencias y recursos adicionales

Para obtener m√°s informaci√≥n sobre la anonimizaci√≥n de datos y la protecci√≥n de datos personales, se pueden consultar:
* Constituci√≥n 
* LEY 21096 Firma electr√≥nica CONSAGRA EL DERECHO A PROTECCI√ìN DE LOS DATOS PERSONALES https://www.bcn.cl/leychile/navegar?idNorma=1119730
* LEY 19628 SOBRE PROTECCION DE LA VIDA PRIVADA https://www.bcn.cl/leychile/navegar?idNorma=141599&idParte=8642700&idVersion=2020-08-26
* 
* LEY 20285 SOBRE ACCESO A LA INFORMACI√ìN P√öBLICA https://www.bcn.cl/leychile/navegar?idNorma=276363]

# El c√≥digo.

##Revisar:
Hay casos de uso del estudio de Langchain que pueden ser utilizados en el c√≥digo

* Modificar salida (Ejemplo 3: de https://claude.ai/chat/07 ... db)
Este callback modifica el texto generado antes de devolverlo, por ejemplo para filtrar palabras inapropiadas:

python

<code> from langchain.callbacks.base import BaseCallbackManager

 class OutputModifier(BaseCallbackManager):
     def on_call_finish(self, fn_name, output):
         return output.replace("palabra_prohibidaXD", "[censurado]")

 callback_manager = OutputModifier()
 llm.add_callback_manager(callback_manager)
 Cualquier ocurrencia de "palabra_prohibidaXD" ser√° reemplazada por "[censurado]" en la salida final.

<code>
